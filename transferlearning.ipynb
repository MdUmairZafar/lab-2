{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdUmairZafar/lab-2/blob/master/transferlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwgk986nTNtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2c0f00-ef43-41b1-cec2-b0eac0058909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image  # Correctly import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from deep_sort.deep_sort import DeepSort\n",
        "from yolov4.tf import YOLOv4\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zip_path = '/content/drive/MyDrive/Dataset1.zip'\n",
        "extract_path = '/content/Dataset1'\n",
        "dataset_path = os.path.join(extract_path, 'train')\n",
        "\n",
        "# Extract Dataset\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Dataset extracted to {extract_path}\")\n",
        "else:\n",
        "    print(f\"Dataset already exists at {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbzn69eBWOqi",
        "outputId": "894f52eb-9543-4a91-cd68-9d9ab3034dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to /content/Dataset1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to clean dataset\n",
        "def clean_dataset(dataset_path):\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                # Attempt to open the file as an image\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # Verify if it's a valid image\n",
        "            except (IOError, SyntaxError):\n",
        "                print(f\"Removing invalid file: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "# Clean the dataset\n",
        "clean_dataset('/content/Dataset1')\n",
        "\n",
        "# Data Preparation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    '/content/Dataset1',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    '/content/Dataset1',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFpsfVjpWngj",
        "outputId": "5635358d-c078-4516-d348-bb9ab96701e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19999 images belonging to 1 classes.\n",
            "Found 4999 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Pre-trained Model\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model.trainable = False  # Freeze base model\n",
        "\n",
        "# Custom Layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(train_data.num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile and Train\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(train_data, validation_data=val_data, epochs=5)\n",
        "\n",
        "# Save Model\n",
        "model_save_path = \"/content/drive/MyDrive/cats_dogs_transfer_learning_model.h5\"\n",
        "model.save(model_save_path)\n",
        "\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3AL78qsf0Z1",
        "outputId": "1f2e6bb3-1971-4f82-e837-148db74fda72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1509s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1516s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1475s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1548s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1513s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/cats_dogs_transfer_learning_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Define the URL and destination file path\n",
        "url = \"https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.weights\"\n",
        "weights_path = \"/content/drive/MyDrive/yolo/yolov4.weights\"\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs(os.path.dirname(weights_path), exist_ok=True)\n",
        "\n",
        "# Download the weights file\n",
        "response = requests.get(url, stream=True)\n",
        "with open(weights_path, \"wb\") as f:\n",
        "    for chunk in response.iter_content(chunk_size=1024):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "\n",
        "print(f\"YOLOv4 weights saved at: {weights_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxGfSjs0OZks",
        "outputId": "3aaad067-5213-494d-ead3-bc713c799079"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv4 weights saved at: /content/drive/MyDrive/yolo/yolov4.weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv4 Model\n",
        "\n",
        "# !pip install yolov4\n",
        "# !git clone https://github.com/theAIGuysCode/yolov4-deepsort\n",
        "# %cd yolov4-deepsort/\n",
        "# !sed -i 's/tensorflow-gpu==2.3.0rc0/tensorflow-gpu==2.9.1/g' requirements-gpu.txt\n",
        "# !pip install deep-sort-realtime\n",
        "\n",
        "\n",
        "\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from yolov4.tf import YOLOv4\n",
        "import cv2\n",
        "\n",
        "yolo = YOLOv4()\n",
        "yolo.config.parse_names(\"/content/drive/MyDrive/yolo/coco.names\")\n",
        "yolo.config.parse_cfg(\"/content/drive/MyDrive/yolo/yolov4.cfg\")\n",
        "yolo.make_model()\n",
        "yolo.load_weights(\"/content/drive/MyDrive/yolo/yolov4.weights\", weights_type=\"yolo\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7iF9ZdKjKPe4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DeepSORT\n",
        "deep_sort = DeepSort(\"/content/drive/MyDrive/deepsort/mars-small128.pb\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QR8ebWiKrZ4",
        "outputId": "73e3ba8d-0d9a-4c85-ce1c-0a707c58b627"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deep_sort_realtime/embedder/embedder_pytorch.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.load_state_dict(torch.load(model_wts_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Test Video\n",
        "video_path = \"/content/drive/MyDrive/test_video.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "out = None"
      ],
      "metadata": {
        "id": "vN9A0DfCKufz"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define Output Writer\n",
        "output_path = \"/content/drive/MyDrive/tracking_output.mp4\"\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    bboxes, scores, classes, _ = yolo.predict(frame, prob_thresh=0.5)\n",
        "\n",
        "    # Convert to DeepSORT Format\n",
        "    detections = []\n",
        "    for bbox, score, cls in zip(bboxes, scores, classes):\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        detections.append((x_min, y_min, x_max - x_min, y_max - y_min, score))\n",
        "\n",
        "    # Update Tracker\n",
        "    tracks = deep_sort.update_tracks(detections, frame=frame)\n",
        "\n",
        "    # Draw Bounding Boxes and IDs\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed() or track.time_since_update > 1:\n",
        "            continue\n",
        "        bbox = track.to_tlbr()  # Get the bounding box in (x_min, y_min, x_max, y_max)\n",
        "        track_id = track.track_id\n",
        "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 0, 0), 2)\n",
        "        cv2.putText(frame, f\"ID: {track_id}\", (int(bbox[0]), int(bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # Write Frame to Output\n",
        "    out.write(frame)\n",
        "\n",
        "    # Display Frame\n",
        "    cv2.imshow('Tracking', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Tracking output saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "GDM8-6TtKyk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}